{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 3), (1000000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xi | ti ~ N(logit(alpha*ti), (beta*ti)^2)\n",
    "# ti ~ N(0,Sigma)\n",
    "\n",
    "N, d = int(1e6), 3\n",
    "alpha = np.linspace(1,d,d)\n",
    "beta = np.random.randint(10, size=d) - 5\n",
    "\n",
    "def data(N, d, alpha, beta):\n",
    "    X = np.random.normal(size = (int(N/1000), d))\n",
    "    X = np.concatenate([X for i in range(1000)], axis=0)\n",
    "    muiY = np.exp(X.dot(alpha)) / (1 + np.exp(X.dot(alpha)))\n",
    "    sigY = X.dot(beta)\n",
    "    preY = np.random.normal(size = (N,))\n",
    "    Y = preY * sigY + muiY\n",
    "    return X, Y\n",
    "\n",
    "X, Y = data(N,d,alpha,beta)\n",
    "Xval, Yval = data(N,d,alpha,beta)\n",
    "\n",
    "Xval.shape, Yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_2 (TensorFlowOpLayer)    [(None, 2)]          0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8\n",
      "Trainable params: 8\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1000000 samples, validate on 1000000 samples\n",
      "Epoch 1/10\n",
      "1000000/1000000 [==============================] - 14s 14us/sample - loss: 2331937.6444 - val_loss: 1456.1262\n",
      "Epoch 2/10\n",
      "1000000/1000000 [==============================] - 14s 14us/sample - loss: 86781.6142 - val_loss: 7113.8534\n",
      "Epoch 3/10\n",
      "1000000/1000000 [==============================] - 14s 14us/sample - loss: 809.3025 - val_loss: 7118.7575\n",
      "Epoch 4/10\n",
      "1000000/1000000 [==============================] - 14s 14us/sample - loss: 809.2528 - val_loss: 7128.1235\n",
      "Epoch 5/10\n",
      "1000000/1000000 [==============================] - 14s 14us/sample - loss: 809.5669 - val_loss: 7128.9668\n",
      "Epoch 6/10\n",
      "1000000/1000000 [==============================] - 14s 14us/sample - loss: 809.6786 - val_loss: 7123.0689\n",
      "Epoch 7/10\n",
      "1000000/1000000 [==============================] - 14s 14us/sample - loss: 809.8803 - val_loss: 7119.4252\n",
      "Epoch 8/10\n",
      "1000000/1000000 [==============================] - 14s 14us/sample - loss: 809.6214 - val_loss: 7129.2445\n",
      "Epoch 9/10\n",
      "1000000/1000000 [==============================] - 14s 14us/sample - loss: 809.4019 - val_loss: 7117.2420\n",
      "Epoch 10/10\n",
      "1000000/1000000 [==============================] - 14s 14us/sample - loss: 809.3950 - val_loss: 7125.0207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5adc46b518>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def densityEncoder(dim):\n",
    "    inputs = tf.keras.Input(shape=(dim,))\n",
    "    \n",
    "    mui = layers.Dense(1, activation='sigmoid')(inputs)\n",
    "    \n",
    "    sig = layers.Dense(1)(inputs)\n",
    "    \n",
    "    outputs = tf.concat([mui,sig],axis=1)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "def densityLoss(Y,theta):\n",
    "    mui, sig2 = theta[:,0], theta[:,-1]**2\n",
    "    negloglike = 0.5 * (tf.math.log(sig2) + (Y-mui)**2 / sig2)\n",
    "    return tf.reduce_mean(negloglike)\n",
    "    \n",
    "model = densityEncoder(d)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-2),\n",
    "              loss=densityLoss)\n",
    "model.summary()\n",
    "\n",
    "model.fit(X, Y, batch_size=int(1e4), epochs=10,\n",
    "          validation_data = (Xval, Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval_para = model.predict(Xval)\n",
    "\n",
    "muiYval = np.exp(Xval.dot(alpha)) / (1 + np.exp(Xval.dot(alpha)))\n",
    "sigYval = Xval.dot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.8529258 , -2.555131  ],\n",
       "        [ 0.3973687 ,  0.36677486],\n",
       "        [ 0.6635228 , -0.87195534],\n",
       "        [ 0.43695098,  0.20318948],\n",
       "        [ 0.6906036 , -1.3628178 ],\n",
       "        [ 0.21290946,  1.3902154 ],\n",
       "        [ 0.38408202, -0.07406573],\n",
       "        [ 0.24752471,  1.204143  ],\n",
       "        [ 0.26783746,  1.3132865 ]], dtype=float32),\n",
       " array([0.9149794 , 0.51191925, 0.038352  , 0.17523856, 0.93273574,\n",
       "        0.26778679, 0.99857431, 0.28219866, 0.03479917]),\n",
       " array([ 0.16173808,  2.57471828, -0.52995873, -0.2426617 ,  0.57716296,\n",
       "        -5.42283007, -3.09905508, -2.22489819,  2.5990025 ]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_para[1:10,:], muiYval[1:10], sigYval[1:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
